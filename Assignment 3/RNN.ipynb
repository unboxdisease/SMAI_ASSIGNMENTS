{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y45yhDufI5Uo"
   },
   "source": [
    "# **RNN**\n",
    "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55i8db8uI5U3"
   },
   "source": [
    "IMDB sentiment classification task\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided.\n",
    "\n",
    "You can download the dataset from http://ai.stanford.edu/~amaas/data/sentiment/  or you can directly use \n",
    "\" from keras.datasets import imdb \" to import the dataset.\n",
    "\n",
    "Few points to be noted:\n",
    "Modules like SimpleRNN, LSTM, Activation layers, Dense layers, Dropout can be directly used from keras\n",
    "For preprocessing, you can use required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8644,
     "status": "ok",
     "timestamp": 1638543504765,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "SozhvLNkI5U6",
    "outputId": "8298d567-19cc-4ae1-9226-b50e9177be19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "#load the imdb dataset \n",
    "from keras.datasets import imdb\n",
    "\n",
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1638543507131,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "NrilwfurI5VA",
    "outputId": "9b854e14-e306-4953-abf3-c2e4e07ae3e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review---\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "---label---\n",
      "1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "---review with words---\n",
      "['the', 'as', 'you', 'with', 'out', 'themselves', 'powerful', 'lets', 'loves', 'their', 'becomes', 'reaching', 'had', 'journalist', 'of', 'lot', 'from', 'anyone', 'to', 'have', 'after', 'out', 'atmosphere', 'never', 'more', 'room', 'and', 'it', 'so', 'heart', 'shows', 'to', 'years', 'of', 'every', 'never', 'going', 'and', 'help', 'moments', 'or', 'of', 'every', 'chest', 'visual', 'movie', 'except', 'her', 'was', 'several', 'of', 'enough', 'more', 'with', 'is', 'now', 'current', 'film', 'as', 'you', 'of', 'mine', 'potentially', 'unfortunately', 'of', 'you', 'than', 'him', 'that', 'with', 'out', 'themselves', 'her', 'get', 'for', 'was', 'camp', 'of', 'you', 'movie', 'sometimes', 'movie', 'that', 'with', 'scary', 'but', 'and', 'to', 'story', 'wonderful', 'that', 'in', 'seeing', 'in', 'character', 'to', 'of', '70s', 'and', 'with', 'heart', 'had', 'shadows', 'they', 'of', 'here', 'that', 'with', 'her', 'serious', 'to', 'have', 'does', 'when', 'from', 'why', 'what', 'have', 'critics', 'they', 'is', 'you', 'that', \"isn't\", 'one', 'will', 'very', 'to', 'as', 'itself', 'with', 'other', 'and', 'in', 'of', 'seen', 'over', 'and', 'for', 'anyone', 'of', 'and', 'br', \"show's\", 'to', 'whether', 'from', 'than', 'out', 'themselves', 'history', 'he', 'name', 'half', 'some', 'br', 'of', 'and', 'odd', 'was', 'two', 'most', 'of', 'mean', 'for', '1', 'any', 'an', 'boat', 'she', 'he', 'should', 'is', 'thought', 'and', 'but', 'of', 'script', 'you', 'not', 'while', 'history', 'he', 'heart', 'to', 'real', 'at', 'and', 'but', 'when', 'from', 'one', 'bit', 'then', 'have', 'two', 'of', 'script', 'their', 'with', 'her', 'nobody', 'most', 'that', 'with', \"wasn't\", 'to', 'with', 'armed', 'acting', 'watch', 'an', 'for', 'with', 'and', 'film', 'want', 'an']\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#the review is stored as a sequence of integers. \n",
    "# These are word IDs that have been pre-assigned to individual words, and the label is an integer\n",
    "\n",
    "print('---review---')\n",
    "print(X_train[0])\n",
    "print('---label---')\n",
    "print(y_train[0])\n",
    "\n",
    "# to get the actual review\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[0]])\n",
    "print('---label---')\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1638543541785,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "h6upWxEWI5VC"
   },
   "outputs": [],
   "source": [
    "#pad sequences (write your code here)\n",
    "from keras.preprocessing import sequence\n",
    "mxlen = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen = mxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = mxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1638543608700,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "-RcCOpeNI5VF",
    "outputId": "f2813b99-3687-4bbd-c03e-16847384c3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 100)               13300     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,401\n",
      "Trainable params: 173,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#design a RNN model (write your code)\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
    "sz = 32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, sz, input_length=500))\n",
    "model.add(SimpleRNN(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1638543614431,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "InQ2TED3I5VI"
   },
   "outputs": [],
   "source": [
    "#train and evaluate your model\n",
    "#choose your loss function and optimizer and mention the reason to choose that particular loss function and optimizer\n",
    "# use accuracy as the evaluation metric\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263868,
     "status": "ok",
     "timestamp": 1638543884462,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "q6A9Q0xmI5VJ",
    "outputId": "57562b5e-e11f-48d0-d0e5-e7987890acc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "390/390 [==============================] - 88s 222ms/step - loss: 0.6731 - accuracy: 0.5671 - val_loss: 0.6558 - val_accuracy: 0.5625\n",
      "Epoch 2/3\n",
      "390/390 [==============================] - 87s 222ms/step - loss: 0.6072 - accuracy: 0.6657 - val_loss: 0.6617 - val_accuracy: 0.6094\n",
      "Epoch 3/3\n",
      "390/390 [==============================] - 87s 222ms/step - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.5123 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa876d33d50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28588,
     "status": "ok",
     "timestamp": 1638543913019,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "YTXG__EmI5VM",
    "outputId": "ed3d7cd9-049b-4eb8-f0b9-03e82427ba27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7743600010871887\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model using model.evaluate()\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1uSo8DgI5VN"
   },
   "source": [
    "# **LSTM**\n",
    "\n",
    "Instead of using a RNN, now try using a LSTM model and compare both of them. Which of those performed better and why ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744877,
     "status": "ok",
     "timestamp": 1638544676869,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "Bk4rLYHwI5VP",
    "outputId": "0eccc8d8-2482-4d1b-da38-ad9c02b64eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "390/390 [==============================] - 233s 592ms/step - loss: 0.4830 - accuracy: 0.7594 - val_loss: 0.2657 - val_accuracy: 0.9062\n",
      "Epoch 2/3\n",
      "390/390 [==============================] - 231s 592ms/step - loss: 0.2925 - accuracy: 0.8824 - val_loss: 0.2579 - val_accuracy: 0.8906\n",
      "Epoch 3/3\n",
      "390/390 [==============================] - 231s 592ms/step - loss: 0.2512 - accuracy: 0.9024 - val_loss: 0.2475 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8769de6d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Embedding(vocabulary_size, 32, input_length=mxlen))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBtRY9jmI5VQ"
   },
   "source": [
    "Perform Error analysis and explain using few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75346,
     "status": "ok",
     "timestamp": 1638544752195,
     "user": {
      "displayName": "Rutvij Menavlikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO2RSiL3jz2Zq0vBys8gaL7l3a2C6KDAdeCoTIpA=s64",
      "userId": "00271061997226666130"
     },
     "user_tz": -330
    },
    "id": "nrs2ylDaI5VR",
    "outputId": "f1240619-aa97-44a4-9088-735024961721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8772799968719482\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2K-M4maMXba"
   },
   "source": [
    "In the concept of RNN, we explore a Memory Unit and some Gates.<br>\n",
    "Upon analysis of the basic structure of the 3 types of RNNs, we find no memory unit in the cells.<br>\n",
    "On increasing number of Mathematical operations of Input($xt$) and previous output ($ct-1$, $ht-1$):\n",
    "- **Simple RNN**: A simple multiplication $xt\\times (ht-1)$ is passed through $tanh$ activation function.\n",
    "- **Gated Recurrent Unit (GRU)**: Here an Update gate is introduced, which decides whether to pass Previous $ht-1$ operations to the next Cell or not. Although Mathematical Operations are performed on same $xt$ and $ht-1$ inputs.\n",
    "- **Long Short Term Memory Unit (LSTM)**: Here, Forget and Output Gates are introduced in addition to Update gate of GRU. Forget gate are additional Mathematical Operations which hav a new set of $wt$ weights. Here too Mathematical Operations are performed on same $xt$ and $ht-1$ inputs. Thus, LSTM has introduced two Math operations which have two new sets of Weights.\n",
    "\n",
    "**Conclusion**:\n",
    "- We can represent the above mentioned Mathematical operations by Taps/Control Nobs.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
